{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54a9c1c",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction — Telecom Company\n",
    "**Author:** : Ali Asadullah Shehbaz\n",
    "\n",
    "**Project Type:** Machine Learning Classification \n",
    " \n",
    "**Objective:** Build a machine learning model to predict customer churn using historical data and provide actionable insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cbb7c",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Customer churn is when a customer stops using a company's service. In telecom, high churn directly impacts revenue and growth. This project builds a predictive model using historical customer data to identify churn risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649afa61",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Objective\n",
    "- Perform Exploratory Data Analysis (EDA)\n",
    "- Engineer features\n",
    "- Train models (Logistic Regression, XGBoost etc)\n",
    "- Evaluate performance using key metrics (confusion matrix, AUC-ROC)\n",
    "- Present results with visualizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f091c",
   "metadata": {},
   "source": [
    "## 3.Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Visualization settings\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d31e4",
   "metadata": {},
   "source": [
    "## 4. Load Data\n",
    "The dataset provided is a mock dataset simulating telecom customer records.  \n",
    "It includes demographic, contract, and payment information along with a churn label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a832494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate mock data\n",
    "np.random.seed(42)\n",
    "n = 10000\n",
    "data = pd.DataFrame({\n",
    "    'CustomerID': np.arange(n),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], size=n),\n",
    "    'SeniorCitizen': np.random.choice([0, 1], size=n),\n",
    "    'Tenure': np.random.randint(1, 72, size=n),\n",
    "    'MonthlyCharges': np.round(np.random.uniform(20, 120, size=n), 2),\n",
    "    'Contract': np.random.choice(['Month-to-month', 'One year', 'Two year'], size=n),\n",
    "    'PaymentMethod': np.random.choice(['Electronic check', 'Mailed check', 'Bank transfer', 'Credit card'], size=n),\n",
    "    'Churn': np.random.choice([0, 1], size=n, p=[0.73, 0.27])\n",
    "})\n",
    "data['TotalCharges'] = (data['Tenure'] * data['MonthlyCharges']).round(2)\n",
    "\n",
    "# Quick check\n",
    "data.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae62dc",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "The goal of EDA is to understand:\n",
    "- Data shape, missing values, and types\n",
    "- Distribution of target variable (Churn)\n",
    "- Relationship between features and churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75564c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {data.shape[0]} rows and {data.shape[1]} columns in the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The columns of the data are : {data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f6e176",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. **Shape & Size**\n",
    "   - **10,000 rows** × **9 columns**.\n",
    "   - Each row represents a unique customer (`CustomerID` from 0 to 9999).\n",
    "\n",
    "2. **Missing Values**\n",
    "   - **No missing values** detected across all columns.\n",
    "\n",
    "3. **Data Types**\n",
    "   - **Integer (`int64`, `int32`)**: `CustomerID`, `SeniorCitizen`, `Tenure`, `Churn`\n",
    "   - **Float (`float64`)**: `MonthlyCharges`, `TotalCharges`\n",
    "   - **Object (categorical)**: `Gender`, `Contract`, `PaymentMethod`\n",
    "\n",
    "4. **Memory Usage**\n",
    "   - Dataset occupies approximately **664 KB** — small enough for in-memory processing.\n",
    "\n",
    "5. **Special Notes**\n",
    "   - `TotalCharges` is derived from `Tenure × MonthlyCharges` and may be **highly correlated** with them.\n",
    "   - All features are fully populated, so no imputation is required at this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum()[data.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull(),cmap = 'magma',cbar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking duplicates in the data \n",
    "data.duplicated('CustomerID').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79783c80",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- No missing values detected.\n",
    "- No duplicate `CustomerID` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic stats\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4af440",
   "metadata": {},
   "source": [
    "### 1. Univariate Analysis\n",
    "We explore distributions of numerical and categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240679ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d69db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=data, x='Gender')\n",
    "plt.title('Gender Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0b9a1",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- There are uniform distribution for gender column in the data with 5000 males and females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4804ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SeniorCitizen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e05009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SeniorCitizen distribution\n",
    "sns.countplot(x='SeniorCitizen', data=data)\n",
    "plt.title(\"SeniorCitizen Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e830f7",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- There are 50% citizens senior and 50% non-senior in the data indicating uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tenure'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure Distribution\n",
    "sns.histplot(x='Tenure', data=data)\n",
    "plt.title('Tenure Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059ae40",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "- The tenure distribution is fairly uniform across the range, with slight peaks around 5, 20, and 55 months, indicating customers join and leave consistently over time rather than clustering at specific contract lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b00d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MonthlyCharges'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='MonthlyCharges',data=data, kde=True)\n",
    "plt.title('Monthly Charges Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db842939",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "- The MonthlyCharges variable appears to be uniformly distributed across its range, with relatively consistent counts in each interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160e895",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6fe3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Contract',data=data)\n",
    "plt.title('Contract Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92701424",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "- The counts of customers are similar across all contract types, with no single type showing a significantly higher or lower number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PaymentMethod'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='PaymentMethod',data=data)\n",
    "plt.title('Payment Method Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54910479",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "- The number of customers using each payment method is nearly equal, indicating no strong preference for any specific payment option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "sns.countplot(x='Churn', data=data)\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7779d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count churn and non-churn\n",
    "churn_counts = data['Churn'].value_counts()\n",
    "\n",
    "# Labels and colors\n",
    "labels = ['No Churn', 'Churn']\n",
    "colors = ['#66b3ff', '#ff9999']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(\n",
    "    churn_counts,\n",
    "    labels=labels,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=colors,\n",
    "    explode=(0, 0.05),  # Slightly explode churn for emphasis\n",
    "    shadow=True\n",
    ")\n",
    "plt.title('Customer Churn Distribution', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b84d5",
   "metadata": {},
   "source": [
    "**Observations**  \n",
    "- The above plot shows that 73.3% People don't churn the bank and Only 26.7% People churn the bank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c213bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TotalCharges'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397358e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TotalCharges Distribution\n",
    "sns.histplot(x='TotalCharges',data=data)\n",
    "plt.title('Total Charges Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003be5a3",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "The TotalCharges distribution is right-skewed, with most customers clustered below $2,000, indicating:\n",
    "- Many are low-spending or short-tenure customers.\n",
    "- A long tail beyond $4,000 suggests a smaller segment of high-value, long-term customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d963402",
   "metadata": {},
   "source": [
    "### 2. Bivariate Analysis\n",
    "We analyze how features differ between churned and non-churned customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e49fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Gender')['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=data, x='Gender', hue='Churn')\n",
    "plt.title('Churn Rate by Gender')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9782fed2",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The churn rates for Male and Female customers appear nearly identical, suggesting that gender has minimal influence on churn in this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95114e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('SeniorCitizen')['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=data, x='SeniorCitizen', hue='Churn')\n",
    "plt.title('Churn Rate by Senior Citizen Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Contract')['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=data, x='Contract', hue='Churn')\n",
    "plt.title('Churn Rate by Contract Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d8cff",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- Customers on month-to-month contracts appear to have a higher proportion of churn compared to one-year and two-year contracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('PaymentMethod')['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=data, x='PaymentMethod', hue='Churn')\n",
    "plt.title('Churn Rate by Payment Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b762b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('MonthlyCharges')['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(data=data, x='MonthlyCharges', hue='Churn')\n",
    "plt.title('Churn Rate by Monthly Charges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e49f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly charges vs Churn\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.boxplot(data=data, x='Churn', y='MonthlyCharges')\n",
    "plt.title('Monthly Charges by Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79545fa6",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "- Monthly Charges column is consistent for both conditions and identical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc294d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=data, x='Churn', y='Tenure')\n",
    "plt.title('Tenure vs Churn')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5001c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=data, x='Churn', y='TotalCharges')\n",
    "plt.title('Total Charges vs Churn')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(data=data, x='Tenure', y='MonthlyCharges', hue='Churn', alpha=0.5)\n",
    "plt.title('Tenure vs Monthly Charges (Colored by Churn)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46291a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract vs Payment Method vs Churn\n",
    "pd.crosstab([data['Contract'], data['PaymentMethod']], data['Churn'], normalize='index') * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee90ea1f",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "-  All the contract categories have the similar churn rate and all the payment methods have similar churn rate with minimal difference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b3922e",
   "metadata": {},
   "source": [
    "### 3. Correlation Analysis\n",
    "We check correlation among numerical features and Churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cae1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "corr = data.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b9326",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Total Charges is 77% correlated with Tenure and 56% correlated with Monthly Charges "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b04738",
   "metadata": {},
   "source": [
    "### 4. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c492e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for each feature to visually inspect outliers\n",
    "num_cols = ['Tenure', 'MonthlyCharges',\n",
    "       'TotalCharges']\n",
    "\n",
    "# Create box plots for each feature to visually inspect outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, feature in enumerate(num_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.boxplot(data[feature], vert=False)\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e1fc9",
   "metadata": {},
   "source": [
    "## 6.Feature Engineering\n",
    "\n",
    "Goal: create informative, non-leaking features and prepare a reproducible preprocessing pipeline for modeling.  \n",
    "Plan:\n",
    "1. Train/test split (stratified on target)\n",
    "2. Basic cleaning & duplicate checks\n",
    "3. Create derived features (tenure buckets, flags, interactions)\n",
    "4. Encode categorical variables (One-Hot / Ordinal / Frequency)\n",
    "5. Scale numeric features\n",
    "6. Check multicollinearity (VIF / correlations) and drop/reduce redundancy\n",
    "7. Save preprocessing pipeline (ColumnTransformer + pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81cd9b",
   "metadata": {},
   "source": [
    "### 1. Train/Test Split\n",
    "Split data into train and test first to avoid leakage during feature engineering (especially for target/statistical encodings).\n",
    "We use stratified splitting to preserve churn ratio in both sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# `data` is our DataFrame and 'Churn' is the target\n",
    "X = data.drop(columns=['Churn', 'CustomerID'])   # drop ID from features\n",
    "y = data['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b15246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de840a",
   "metadata": {},
   "source": [
    "### 2. Basic Data Checks (train set)\n",
    "Check for duplicates, invalid types, and missing values in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f57ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values and duplicates on train\n",
    "print(\"Missing values per column (train):\\n\", X_train.isnull().sum())\n",
    "print(\"Duplicate Customer rows (train):\", X_train.duplicated().sum())\n",
    "# dtype overview\n",
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36520418",
   "metadata": {},
   "source": [
    "### 3. Derived Features\n",
    "Create features that capture business intuition:\n",
    "- `TenureGroup` (binned tenure)\n",
    "- `HighMonthlyFlag` (customers paying above median)\n",
    "- `Contract_Ord` (ordinal mapping for contract length)\n",
    "- `AutoPay` flag (bank transfer / credit card → likely auto-pay)\n",
    "- `AvgChargesPerMonth` (TotalCharges / Tenure) — note: in this synthetic data it's identical to MonthlyCharges; we use it for demonstration and will handle redundancy later.\n",
    "- `Contract_Payment` (combined category) to capture interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96432c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on training copy\n",
    "train = X_train.copy()\n",
    "\n",
    "# Tenure groups (example bins)\n",
    "bins = [0, 3, 6, 12, 24, 48, 72]\n",
    "labels = [\n",
    "    'New (0-3 months)',\n",
    "    'Early (4-6 months)',\n",
    "    'Settling (7-12 months)',\n",
    "    'Engaged (13-24 months)',\n",
    "    'Loyal (25-48 months)',\n",
    "    'Very Loyal (49-72 months)'\n",
    "]\n",
    "train['TenureGroup'] = pd.cut(train['Tenure'], bins=bins, labels=labels, include_lowest=True)\n",
    "# Average charges per month\n",
    "train['AvgChargesPerMonth'] = (train['TotalCharges'] / train['Tenure'])\n",
    "# High monthly flag\n",
    "median_charge = train['MonthlyCharges'].median()\n",
    "train['HighMonthlyFlag'] = (train['MonthlyCharges'] > median_charge).astype(int)\n",
    "# Contract ordinal\n",
    "contract_map = {'Month-to-month': 0, 'One year': 1, 'Two year': 2}\n",
    "train['Contract_Ord'] = train['Contract'].map(contract_map)\n",
    "\n",
    "# Autopay flag (assumption: bank transfer & credit card => auto)\n",
    "autopay_methods = ['Bank transfer', 'Credit card']\n",
    "train['AutoPay'] = train['PaymentMethod'].isin(autopay_methods).astype(int)\n",
    "\n",
    "# Interaction feature (contract + payment)\n",
    "train['Contract_Payment'] = train['Contract'].astype(str) + '_' + train['PaymentMethod'].astype(str)\n",
    "\n",
    "# Quick peek\n",
    "train[['Tenure', 'TenureGroup', 'MonthlyCharges', 'HighMonthlyFlag', 'Contract', 'Contract_Ord', 'AutoPay', 'Contract_Payment','AvgChargesPerMonth']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a46ea",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "- We can do the same deterministic derived feature creation to X_test (below we’ll create a pipeline so this is automatic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5de1e",
   "metadata": {},
   "source": [
    "### 4. Categorical Encoding Strategy\n",
    "- Use One-Hot encoding for `PaymentMethod`, `TenureGroup`, and `Contract_Payment`.\n",
    "- Use ordinal mapping for `Contract` (already created as `Contract_Ord`).\n",
    "- Map `Gender` to binary (Male=1, Female=0) for simplicity.\n",
    "- For target encoding (only if many categories), use KFold target mean encoding on TRAIN only to avoid leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9128308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "# Columns\n",
    "num_cols = ['Tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargesPerMonth']\n",
    "num_cols = [c for c in num_cols if c in X_train.columns]  # defensive\n",
    "\n",
    "# categorical columns\n",
    "cat_cols = ['Gender','PaymentMethod', 'TenureGroup', 'Contract_Payment']\n",
    "\n",
    "# build transformer\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "], remainder='drop')  # drop anything else\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8664ba",
   "metadata": {},
   "source": [
    "### 5. Multicollinearity & Redundancy\n",
    "`TotalCharges` is mathematically derived (Tenure × MonthlyCharges) and shows very high correlation with Tenure (77%). To avoid multicollinearity, we can:\n",
    "- Option A: Drop `TotalCharges` (recommended when derived).\n",
    "- Option B: Keep `TotalCharges` and drop `MonthlyCharges` or `Tenure`.\n",
    "- Option C: Keep only `AvgChargesPerMonth` and `Tenure` (remove direct multiply redundancy).\n",
    "We will compute VIF and pick the safest choice (drop `TotalCharges` in this synthetic dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for correlation \n",
    "plt.figure(figsize=(8,6))\n",
    "corr = train[['Tenure','MonthlyCharges','TotalCharges','AvgChargesPerMonth']].corr()\n",
    "sns.heatmap(corr, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF (optional) — requires statsmodels\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "X_vif = train[['Tenure','MonthlyCharges','TotalCharges','AvgChargesPerMonth']]\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X_vif.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b19394f",
   "metadata": {},
   "source": [
    "During **VIF (Variance Inflation Factor)** analysis, the following results were observed:\n",
    "\n",
    "| Feature              | VIF       |\n",
    "|----------------------|-----------|\n",
    "| Tenure               | 6.99      |\n",
    "| MonthlyCharges       | ∞         |\n",
    "| TotalCharges         | 10.17     |\n",
    "| AvgChargesPerMonth   | ∞         |\n",
    "\n",
    "🔍 R**eason for High VIF**:\n",
    "- **Perfect or near-perfect multicollinearity** exists because:\n",
    "  - `TotalCharges ≈ Tenure × MonthlyCharges`\n",
    "  - `AvgChargesPerMonth = TotalCharges / Tenure` (essentially the same as `MonthlyCharges`)\n",
    "- These relationships mean that some columns are *linear combinations* of others, leading to inflated or infinite VIF values.\n",
    "\n",
    "✅ **Decision**:\n",
    "- **Keep:**  \n",
    "  - `Tenure` → Represents customer relationship duration.  \n",
    "  - `MonthlyCharges` → Represents ongoing cost to the customer.  \n",
    "- **Drop:**  \n",
    "  - `TotalCharges` → Fully derived from `Tenure` and `MonthlyCharges`.  \n",
    "  - `AvgChargesPerMonth` → Redundant with `MonthlyCharges`.\n",
    "\n",
    "💡 **Justification**:\n",
    "- Retaining **raw, base variables** (Tenure, MonthlyCharges) ensures **interpretability** and avoids information leakage.\n",
    "- Removing **derived features** eliminates perfect multicollinearity, making the model more stable and coefficients more reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7d2b9",
   "metadata": {},
   "source": [
    "### 6. Final Preprocessing Pipeline\n",
    "- Drop `TotalCharges` and `AvgChargesPerMonth` (redundant).\n",
    "- Use the pipeline (ColumnTransformer) to transform train and test consistently.\n",
    "- Save the pipeline artifact for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63084fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30888e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant columns from numeric list if you decide to drop it\n",
    "num_cols = [c for c in num_cols if c not in ['TotalCharges' , 'AvgChargesPerMonth'] ]\n",
    "\n",
    "# Reconstruct preprocessor with updated numeric list\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "# Full pipeline (preprocessing + optional dimensionality reduction or model later)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit-transform on training data (we need to ensure train has created derived cols)\n",
    "# Recreate derived features on X_train before fit\n",
    "def create_features(data):\n",
    "    data = data.copy()\n",
    "    data['AvgChargesPerMonth'] = (data['TotalCharges'] / data['Tenure'])\n",
    "    data['TenureGroup'] = pd.cut(data['Tenure'], bins=bins, labels=labels, include_lowest=True)\n",
    "    data['HighMonthlyFlag'] = (data['MonthlyCharges'] > median_charge).astype(int)\n",
    "    data['Contract_Ord'] = data['Contract'].map(contract_map)\n",
    "    data['AutoPay'] = data['PaymentMethod'].isin(autopay_methods).astype(int)\n",
    "    data['Contract_Payment'] = data['Contract'].astype(str) + '_' + data['PaymentMethod'].astype(str)\n",
    "    return data\n",
    "\n",
    "X_train_fe = create_features(X_train)\n",
    "X_test_fe = create_features(X_test)\n",
    "\n",
    "preprocessing_pipeline.fit(X_train_fe)\n",
    "X_train_processed = preprocessing_pipeline.transform(X_train_fe)\n",
    "X_test_processed = preprocessing_pipeline.transform(X_test_fe)\n",
    "\n",
    "print(\"Processed train shape:\", X_train_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c6cf8",
   "metadata": {},
   "source": [
    "### 7. Feature Selection & Dimensionality\n",
    "After preprocessing, consider:\n",
    "- Using `SelectKBest` or `SelectFromModel` (tree-based) to reduce features.\n",
    "- Checking feature importances from a baseline tree (RandomForest/XGBoost) to prune weak features.\n",
    "- Keeping a final feature list saved for production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# quick baseline to get importances (use processed features)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_processed, y_train)\n",
    "\n",
    "sfm = SelectFromModel(rf, threshold='median', prefit=True)\n",
    "X_train_sel = sfm.transform(X_train_processed)\n",
    "X_test_sel = sfm.transform(X_test_processed)\n",
    "print(\"Selected features shape:\", X_train_sel.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74e52b",
   "metadata": {},
   "source": [
    "#### Checklist — Feature Engineering Complete\n",
    "- [ ] Train/test split done (stratified)\n",
    "- [ ] Derived features created (TenureGroup, HighMonthlyFlag, AutoPay, Contract_Payment)\n",
    "- [ ] Redundancy handled (drop `TotalCharges`,`AvgChargesPerMonth `or keep with caution)\n",
    "- [ ] Encoding pipeline implemented (Label Encoder)\n",
    "- [ ] Numeric scaling applied (StandardScaler)\n",
    "- [ ] Feature selection tested (RandomForest + SelectFromModel)\n",
    "\n",
    "**Next step:** use the processed training data (`X_train_processed` or selected version) to train baseline models (Logistic Regression, RandomForest, XGBoost) and compare metrics (accuracy, precision, recall, F1, ROC-AUC).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f061b",
   "metadata": {},
   "source": [
    "## 8. Model Training\n",
    "We’ll test the following classifiers:\n",
    "1. Logistic Regression\n",
    "1. Support Vector Machine (SVM)\n",
    "1. Decision Tree\n",
    "1. Random Forest\n",
    "2. AdaBoost\n",
    "3. XGBoost\n",
    "4. LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9a8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Models and params\n",
    "models = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\n",
    "        \"C\": [0.01, 0.1, 1, 10],\n",
    "        \"penalty\": ['l2']\n",
    "    }),\n",
    "    \"SVM\": (SVC(probability=True), {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"kernel\": ['linear', 'rbf'],\n",
    "        \"gamma\": ['scale', 'auto']\n",
    "    }),\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(), {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [5, 10, None]\n",
    "    }),\n",
    "    \"AdaBoost\": (AdaBoostClassifier(), {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"learning_rate\": [0.01, 0.1, 1]\n",
    "    }),\n",
    "    \"XGBoost\": (XGBClassifier(eval_metric='mlogloss', use_label_encoder=False), {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2]\n",
    "    }),\n",
    "    \"LightGBM\": (LGBMClassifier(objective='binary', random_state=42), {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [-1, 5, 10],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"num_leaves\": [31, 50, 100]\n",
    "    })\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd61a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To store model results\n",
    "results = []\n",
    "\n",
    "best_model = None\n",
    "best_auc = 0\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    grid = GridSearchCV(model, params, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "    grid.fit(X_train_sel, y_train)\n",
    "    \n",
    "    y_pred = grid.predict(X_test_sel)\n",
    "    y_proba = grid.predict_proba(X_test_sel)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_proba[:,1])\n",
    "    \n",
    "    # Save results for DataFrame\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best_Params': grid.best_params_,\n",
    "        'ROC_AUC': auc\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name} | Best Params: {grid.best_params_} | AUC: {auc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if auc > best_auc:\n",
    "        best_auc = auc\n",
    "        best_model = (name, grid.best_estimator_)\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "results_df = pd.DataFrame(results).sort_values(by='ROC_AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cc970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\\nBest Model: {best_model[0]} with AUC = {best_auc:.4f}\")\n",
    "print(\"\\n=== Model Performance Summary (Sorted by ROC AUC) ===\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345bf2dd",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation\n",
    "We compare models using:\n",
    "- Confusion Matrix\n",
    "- Classification Report\n",
    "- AUC-ROC Curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e448866",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = best_model[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3423ebd",
   "metadata": {},
   "source": [
    "- Best Model is saved with the name \"final_model\" to use for the prediction and evaluation later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8300d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is already trained\n",
    "y_prob = final_model.predict_proba(X_test_sel)[:, 1]  # Take probability of positive class\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], '--')  # random baseline\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8da2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Option 1: Using seaborn heatmap\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Stay', 'Churn'], \n",
    "            yticklabels=['Stay', 'Churn'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix - Best Model')\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')  # High quality, trimmed edges\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ff83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by ROC_AUC for better visualization\n",
    "results_df = results_df.sort_values('ROC_AUC', ascending=False)\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='ROC_AUC', y='Model', data=results_df, palette='Blues_d')\n",
    "\n",
    "# Add values on bars\n",
    "for index, value in enumerate(results_df['ROC_AUC']):\n",
    "    plt.text(value + 0.001, index, f\"{value:.4f}\", va='center', fontsize=10)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Model Comparison by ROC AUC', fontsize=14)\n",
    "plt.xlabel('ROC AUC Score')\n",
    "plt.ylabel('Model')\n",
    "plt.xlim(0.48, 0.53)  # zoom in for clarity\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"barplot of models.png\", dpi=300, bbox_inches='tight')  # High quality, trimmed edges\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d705f",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "- **Best Model:** XGBoost achieved higher AUC-ROC compared to Logistic Regression.\n",
    "- Customers on month-to-month contracts have a higher churn rate.\n",
    "- Higher monthly charges correlate with higher churn.\n",
    "\n",
    "## 11. Recommendations\n",
    "- Offer loyalty discounts for month-to-month customers.\n",
    "- Investigate reasons for high charges leading to churn.\n",
    "- Consider targeted marketing campaigns for high-risk customers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
